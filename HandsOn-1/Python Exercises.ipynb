{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1\n",
    "\n",
    "The goal of this problem is to break a block of text into lines of at most a certain length.\n",
    "\n",
    "### Step 1\n",
    "Write a funcion that takes a string `text` and a number `max_len` as parameters and returns the longest list of words from the beginning of `text` such that the sum of their lengths is no more than `max_len`. For example, if the `text` is `\"Hey you,   get up!\"` and `max_length` is 12, the result is `[\"Hey\", \"you,\", \"get\"]`.\n",
    "\n",
    "### Step 2\n",
    "Write a funcion that takes a string `text` and a number `max_len` as parameters and returns a list of strings obtained from breaking `text` into a number of strings, each of length no more than `max_len`, assuming each string is a sequence of words separated by one space character. For example, if `text` is `\"Slides transition   using a  fade animation by default.\"` and `max_len` is 20, the result will be `[\"Slides transition\", \"using a fade\", \"animation by\", \"default.\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "The goal is to generate random sentences based on a simple language model constructed from a relatively long text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "Write a function named `remove_punct` to replace all punctuation characters in a given text with a space character, except periods ('.'). For example,\n",
    "```Python\n",
    "remove_punct(\"hi! 'howdy?' i'm here-for you. Come with me.\")\n",
    "```\n",
    "returns\n",
    "```\n",
    "'hi   howdy   i m here for you. Come with me.'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Write a function named `tokenize2` to return the list of words in a text, including periods ('.'). For example,\n",
    "```Python\n",
    "tokenize2(\"hi! 'howdy?' i'm here-for you. Come with me.\")\n",
    "```\n",
    "returns\n",
    "```\n",
    "['hi', 'howdy', 'im', 'herefor', 'you', '.', 'come', 'with', 'me', '.']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "Replacing `tokenize` by `tokenize2` in our bigram model construction code results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_freq2(s):\n",
    "    tokens = tokenize2(s)\n",
    "    result = {}\n",
    "    for i in range(len(tokens)-1):\n",
    "        bigram = (tokens[i], tokens[i+1])\n",
    "        if not bigram in result:\n",
    "            result[bigram] = 1\n",
    "        else:\n",
    "            result[bigram] = result[bigram] + 1\n",
    "    return result\n",
    "\n",
    "def construct_model2(text):\n",
    "    model = dict.fromkeys(tokenize2(text))\n",
    "    for word in model:\n",
    "        model[word] = {}\n",
    "    bi_freqs = bigram_freq2(text)\n",
    "    for bigram in bi_freqs:\n",
    "        model[bigram[0]][bigram[1]] = bi_freqs[bigram]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Write a function named `construct_model_from_file` that takes a filename and produces the bigram language model using `construct_model2` defined above.\n",
    "\n",
    "For example, `construct_model_from_file(\"CrimeAndPunishment.txt\")` results in a model whose first elements are like:\n",
    "```\n",
    "{'crime': {'and': 4,\n",
    "  'be': 1,\n",
    "  'as': 1,\n",
    "  'continued': 1,\n",
    "  'or': 1,\n",
    "  'from': 1,\n",
    "  '.': 10,\n",
    "  'the': 1,\n",
    "  'i': 3,\n",
    "  'he': 2,\n",
    "  'has': 1,\n",
    "  \n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "Write a function `suggest_words(model, word, n)` that suggest `n` words that have the highest frequencies of immediately following `word`, according to the language model `model`. Set a default value of 3 for `n`.\n",
    "\n",
    "For example, if `cp_model` is a variable refering to the model constructed from `CrimeAndPunishment.txt`, `suggest_words(cp_model, 'I')` returns `['am', 'have', 'was']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "Write a function `suggest_random_word(model, word)` that suggests a word to follow `word` randomly, according to uniform distribution obtained from the frequencies of the word that follow `word` in the `model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "Write a function `gen_random_sentence(model, word, max_words)` that generates a random sentence which begins with `word` and has at most `max_words` words (or else ends with a period). Use `suggest_random_word` function from the previous steps.\n",
    "\n",
    "Use this function to generate sentences in the style of Balzac and Dostoevsky!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 8\n",
    "Function `zip` \"pairs\" up the elements of a number of lists to create a list of tuples:\n",
    "```Python\n",
    "list1 = ['one', 'two', 'three']\n",
    "list2 = ['cat', 'dog', 'cow']\n",
    "zipped = zip(list1, list2)\n",
    "list(zipped) # [('one', 'cat'), ('two', 'dog'), ('three', 'cow')]\n",
    "```\n",
    "\n",
    "Using `zip`, list all bigrams of a text.\n",
    "*Hint: slicing operation may be useful.*"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
